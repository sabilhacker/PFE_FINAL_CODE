{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd8b4ca-7437-44d6-bbf0-859200143274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from timeit import default_timer as timer\n",
    "from typing import Callable, Optional, Union, List, Dict, Any, Sequence\n",
    "import json\n",
    "from functools import partial\n",
    "from qiskit.circuit.library import ZZFeatureMap, TwoLocal\n",
    "from qiskit.circuit.library import EfficientSU2, RealAmplitudes\n",
    "\n",
    "\n",
    "# Qiskit imports\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "\n",
    "# Qiskit Machine Learning requirements\n",
    "from qiskit_machine_learning.kernels import (\n",
    "    FidelityStatevectorKernel,\n",
    "    TrainableKernel,\n",
    "    TrainableFidelityStatevectorKernel,\n",
    ")\n",
    "from qiskit_machine_learning.kernels.algorithms import QuantumKernelTrainer\n",
    "from qiskit_machine_learning.utils.loss_functions import SVCLoss\n",
    "from qiskit_machine_learning.algorithms.classifiers import QSVC\n",
    "\n",
    "from qiskit_algorithms.optimizers import SPSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6acc8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df= pd.read_csv('Datasets/dataset_selected_features.csv')\n",
    "X = df.drop(columns=['Label_Malicious'])\n",
    "y = df['Label_Malicious']\n",
    "\n",
    "# Split your full dataset into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X.values, y.values, test_size=0.33, random_state=42, stratify=y.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed802a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in training labels: [0. 1.]\n",
      "Unique classes in test labels: [0. 1.]\n",
      "Number of classes in training labels: 2\n",
      "Number of classes in test labels: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming train_labels and test_labels are your label arrays\n",
    "unique_train_classes = np.unique(y_train)\n",
    "unique_test_classes = np.unique(y_test)\n",
    "\n",
    "print(\"Unique classes in training labels:\", unique_train_classes)\n",
    "print(\"Unique classes in test labels:\", unique_test_classes)\n",
    "print(\"Number of classes in training labels:\", len(unique_train_classes))\n",
    "print(\"Number of classes in test labels:\", len(unique_test_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c06010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_qubits = X.shape[1]\n",
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension=num_qubits, reps=2 , entanglement='linear')\n",
    "\n",
    "var_layer = TwoLocal(num_qubits=num_qubits,\n",
    "                     rotation_blocks=['ry', 'rz'],\n",
    "                     entanglement_blocks='cz',\n",
    "                     entanglement='linear',\n",
    "                     reps=1,\n",
    "                     insert_barriers=True)\n",
    "\n",
    "var_feature_map = feature_map.compose(var_layer)\n",
    "\n",
    "feature_params = feature_map.parameters               # dataset-dependent\n",
    "variational_params = var_layer.parameters             # trainable\n",
    "\n",
    "# Get variational (trainable) parameters\n",
    "trainable_params = list(var_layer.parameters)   # not from var_feature_map\n",
    "\n",
    "# Initialize values for training parameters\n",
    "init_p = 0.25 * np.random.uniform(-np.pi, np.pi, len(trainable_params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1baaf226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.32397058  0.12001553 -0.14784499 -0.18021386 -0.06911982 -0.70494077\n",
      " -0.13842304 -0.19646906 -0.75135399  0.7616688  -0.07084935  0.01155279\n",
      " -0.65692906 -0.44676391  0.22926334  0.48693151 -0.58154689  0.06384499\n",
      " -0.20945453 -0.52071531 -0.69055224  0.28409528  0.02863196  0.33058916\n",
      "  0.01521392 -0.73991161 -0.70880685 -0.25111838  0.75596863 -0.06299543\n",
      "  0.75583834 -0.15382136]\n"
     ]
    }
   ],
   "source": [
    "optimizers = [\"SPSA\"]\n",
    "batch_sizes = [1000]\n",
    "sub_kernel_sizes = [1000]\n",
    "batch_types = [True]\n",
    "results = {}\n",
    "print(init_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42beef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# from utils.Batches import BatchedSVCLoss\n",
    "# from utils.opt import get_optimizer_options\n",
    "# from utils.pegasosqsvc import run_PegasosQSVC\n",
    "# from utils.plots import plot_average_loss_with_variance\n",
    "# from utils.qktcallback import QKTCallback\n",
    "\n",
    "\n",
    "# for opt in optimizers:\n",
    "#     opt_results = []\n",
    "#     for sub_kernel_size in sub_kernel_sizes:\n",
    "#         for batch_size in batch_sizes:\n",
    "#             if sub_kernel_size == None:\n",
    "#                 if batch_size != 1:\n",
    "#                     continue\n",
    "#             for batch_type in batch_types:\n",
    "#                 if sub_kernel_size == None:\n",
    "#                     sk_size = len(X_train)\n",
    "#                     if batch_type == True:\n",
    "#                         continue\n",
    "#                 else:\n",
    "#                     sk_size = int(sub_kernel_size)\n",
    "#                 print(\"=\" * 50)\n",
    "#                 print(\"Training with \", opt, \" optimizer.\")\n",
    "#                 print(\n",
    "#                     \"Currently using subkernel size: \",\n",
    "#                     sub_kernel_size,\n",
    "#                     \" where loss is averaged over \",\n",
    "#                     batch_size,\n",
    "#                     \" loss.\",\n",
    "#                 )\n",
    "#                 print(\"Sub-kernels prepared according to Balanced:\", batch_type)\n",
    "#                 print(\"=\" * 50)\n",
    "#                 cb, optimizer = get_optimizer_options(opt)\n",
    "#                 if cb == \"SPSACallback\":\n",
    "#                     callb = QKTCallback()\n",
    "#                     optimizer = optimizer(callback=callb.callback)\n",
    "#                 else:\n",
    "#                     optimizer = optimizer()\n",
    "               \n",
    "#                 qk = TrainableFidelityStatevectorKernel(\n",
    "#                     feature_map=var_feature_map, training_parameters=var_layer.parameters,\n",
    "#                 )\n",
    "#                 # Instantiate Sub-kernel loss\n",
    "#                 loss = BatchedSVCLoss(\n",
    "#                     X_train,\n",
    "#                     y_train,\n",
    "#                     minibatch_size=batch_size,\n",
    "#                     sub_kernel_size=sub_kernel_size,\n",
    "#                     balanced_batch=batch_type,\n",
    "#                     shuffle=True,\n",
    "#                     encoder=None,\n",
    "#                 )\n",
    "#                 # Instantiate a quantum kernel trainer.\n",
    "#                 qkt = QuantumKernelTrainer(\n",
    "#                     quantum_kernel=qk,\n",
    "#                     loss=loss,\n",
    "#                     optimizer=optimizer,\n",
    "#                     initial_point=init_p\n",
    "#                 )\n",
    "#                 # Train the kernel\n",
    "#                 start = timer()\n",
    "#                 qka_results = qkt.fit(X_train, y_train)\n",
    "#                 end = timer()\n",
    "#                 train_time = end - start\n",
    "#                 print(f\" Training Runtime: {train_time} secs. Results: \")\n",
    "#                 print()\n",
    "#                 # print('-'*80)\n",
    "#                 # print(qka_results)\n",
    "#                 # print('-'*80)\n",
    "#                 # print()\n",
    "#                 # print(\"Evaluating optimized kernel with the optimal parameters...\")\n",
    "#                 optimized_kernel = qka_results.quantum_kernel\n",
    "\n",
    "#                 start = timer()\n",
    "\n",
    "#                 # Train the QSVC using optimized quantum fidelity kernel\n",
    "#                 qsvc, auc, f1, accuracy = run_PegasosQSVC(\n",
    "#                     X_train,\n",
    "#                     y_train,\n",
    "#                     X_test,\n",
    "#                     y_test,\n",
    "#                     optimized_kernel,\n",
    "#                 )\n",
    "#                 end = timer()\n",
    "#                 qsvc_runtime = end - start\n",
    "#                 num_support_vectors = len(qsvc.support_)\n",
    "\n",
    "#                 print(f\"QSVC Training Runtime: {qsvc_runtime} secs\")\n",
    "\n",
    "#                 # Print results\n",
    "#                 print(\"-\" * 50)\n",
    "#                 print(\"F1 Score = %.3f\" % (f1))\n",
    "#                 print(\"ROC AUC = %.3f\" % (auc))\n",
    "#                 print(\"Accuracy Score = %.3f\" % (accuracy))\n",
    "#                 print()\n",
    "#                 print()\n",
    "\n",
    "#                 # Get the training loss\n",
    "#                 plot_data = (\n",
    "#                     len(X_train) * np.array(loss.loss_arr) / (sk_size * num_support_vectors)\n",
    "#                 )\n",
    "\n",
    "#                 # Plotting\n",
    "#                 plot_average_loss_with_variance(plot_data, N=20)\n",
    "\n",
    "#                 # Append the results\n",
    "#                 opt_results.append(\n",
    "#                     {\n",
    "#                         \"ROC\": auc,\n",
    "#                         \"F1\": f1,\n",
    "#                         \"accuracy\": accuracy,\n",
    "#                         \"sub_kernel_size\": sub_kernel_size,\n",
    "#                         \"batch_size\": batch_size,\n",
    "#                         \"Balanced\": batch_type,\n",
    "#                         \"train_time\": train_time,\n",
    "#                         \"qsvc_runtime\": qsvc_runtime,\n",
    "#                         \"training_loss\": plot_data.tolist(),\n",
    "#                         \"loss\": loss.loss_arr,\n",
    "#                         \"opt_params\": qka_results.optimal_point.tolist(),\n",
    "#                     }\n",
    "#                 )\n",
    "#     results.update({opt: opt_results})\n",
    "\n",
    "# with open(\"Subkernel_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(results, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8210b05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found, starting fresh.\n",
      "==================================================\n",
      "Training with SPSA optimizer.\n",
      "Currently using subkernel size: 1000, where loss is averaged over 1000 loss.\n",
      "Sub-kernels prepared according to Balanced: True\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from utils.Batches import BatchedSVCLoss\n",
    "from utils.opt import get_optimizer_options\n",
    "from utils.pegasosqsvc import run_PegasosQSVC\n",
    "from utils.plots import plot_average_loss_with_variance\n",
    "from utils.qktcallback import QKTCallback\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Checkpoint file path\n",
    "checkpoint_file = \"checkpoint_subkernel_results.json\"\n",
    "\n",
    "# Load existing checkpoint if it exists\n",
    "if os.path.exists(checkpoint_file):\n",
    "    with open(checkpoint_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        results = json.load(f)\n",
    "    print(\"Loaded checkpoint from\", checkpoint_file)\n",
    "    \n",
    "    # Calculate and display initial progress\n",
    "    total_combinations = len(optimizers) * len(sub_kernel_sizes) * len(batch_sizes) * len(batch_types)\n",
    "    completed = sum(len(results.get(opt, [])) for opt in results.keys())\n",
    "    print(f\"Progress: {completed}/{total_combinations} combinations completed ({completed/total_combinations*100:.1f}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\"No checkpoint found, starting fresh.\")\n",
    "\n",
    "for opt in optimizers:\n",
    "    # Initialize results for this optimizer if not already present\n",
    "    if opt not in results:\n",
    "        results[opt] = []\n",
    "    opt_results = results[opt]\n",
    "\n",
    "    for sub_kernel_size in sub_kernel_sizes:\n",
    "        for batch_size in batch_sizes:\n",
    "            if sub_kernel_size is None:\n",
    "                if batch_size != 1:\n",
    "                    continue\n",
    "            for batch_type in batch_types:\n",
    "                if sub_kernel_size is None:\n",
    "                    sk_size = len(X_train)\n",
    "                    if batch_type:\n",
    "                        continue\n",
    "                else:\n",
    "                    sk_size = int(sub_kernel_size)\n",
    "\n",
    "                # Check if this combination already exists in results\n",
    "                combination_exists = any(\n",
    "                    res[\"sub_kernel_size\"] == sub_kernel_size and\n",
    "                    res[\"batch_size\"] == batch_size and\n",
    "                    res[\"Balanced\"] == batch_type\n",
    "                    for res in opt_results\n",
    "                )\n",
    "                if combination_exists:\n",
    "                    print(f\"Skipping already processed: {opt}, sub_kernel_size={sub_kernel_size}, batch_size={batch_size}, batch_type={batch_type}\")\n",
    "                    continue\n",
    "\n",
    "                print(\"=\" * 50)\n",
    "                print(f\"Training with {opt} optimizer.\")\n",
    "                print(\n",
    "                    f\"Currently using subkernel size: {sub_kernel_size}, \"\n",
    "                    f\"where loss is averaged over {batch_size} loss.\"\n",
    "                )\n",
    "                print(f\"Sub-kernels prepared according to Balanced: {batch_type}\")\n",
    "                print(\"=\" * 50)\n",
    "\n",
    "                cb, optimizer = get_optimizer_options(opt)\n",
    "                if cb == \"SPSACallback\":\n",
    "                    callb = QKTCallback()\n",
    "                    optimizer = optimizer(callback=callb.callback)\n",
    "                else:\n",
    "                    optimizer = optimizer()\n",
    "\n",
    "                qk = TrainableFidelityStatevectorKernel(\n",
    "                    feature_map=var_feature_map, training_parameters=var_layer.parameters,\n",
    "                )\n",
    "                # Instantiate Sub-kernel loss\n",
    "                loss = BatchedSVCLoss(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    minibatch_size=batch_size,\n",
    "                    sub_kernel_size=sub_kernel_size,\n",
    "                    balanced_batch=batch_type,\n",
    "                    shuffle=True,\n",
    "                    encoder=None,\n",
    "                )\n",
    "                # Instantiate a quantum kernel trainer\n",
    "                qkt = QuantumKernelTrainer(\n",
    "                    quantum_kernel=qk,\n",
    "                    loss=loss,\n",
    "                    optimizer=optimizer,\n",
    "                    initial_point=init_p\n",
    "                )\n",
    "                # Train the kernel\n",
    "                start = timer()\n",
    "                qka_results = qkt.fit(X_train, y_train)\n",
    "                end = timer()\n",
    "                train_time = end - start\n",
    "                print(f\"Training Runtime: {train_time} secs. Results: \")\n",
    "                print()\n",
    "\n",
    "                optimized_kernel = qka_results.quantum_kernel\n",
    "\n",
    "                start = timer()\n",
    "                # Train the QSVC using optimized quantum fidelity kernel\n",
    "                qsvc, auc, f1, accuracy = run_PegasosQSVC(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                    optimized_kernel,\n",
    "                )\n",
    "                end = timer()\n",
    "                qsvc_runtime = end - start\n",
    "                num_support_vectors = len(qsvc.support_)\n",
    "\n",
    "                print(f\"QSVC Training Runtime: {qsvc_runtime} secs\")\n",
    "\n",
    "                # Print results\n",
    "                print(\"-\" * 50)\n",
    "                print(f\"F1 Score = {f1:.3f}\")\n",
    "                print(f\"ROC AUC = {auc:.3f}\")\n",
    "                print(f\"Accuracy Score = {accuracy:.3f}\")\n",
    "                print()\n",
    "                print()\n",
    "\n",
    "                # Get the training loss\n",
    "                plot_data = (\n",
    "                    len(X_train) * np.array(loss.loss_arr) / (sk_size * num_support_vectors)\n",
    "                )\n",
    "\n",
    "                # Plotting\n",
    "                plot_average_loss_with_variance(plot_data, N=20)\n",
    "\n",
    "                # Append the results\n",
    "                opt_results.append(\n",
    "                    {\n",
    "                        \"ROC\": auc,\n",
    "                        \"F1\": f1,\n",
    "                        \"accuracy\": accuracy,\n",
    "                        \"sub_kernel_size\": sub_kernel_size,\n",
    "                        \"batch_size\": batch_size,\n",
    "                        \"Balanced\": batch_type,\n",
    "                        \"train_time\": train_time,\n",
    "                        \"qsvc_runtime\": qsvc_runtime,\n",
    "                        \"training_loss\": plot_data.tolist(),\n",
    "                        \"loss\": loss.loss_arr,\n",
    "                        \"opt_params\": qka_results.optimal_point.tolist(),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                # Save checkpoint after each iteration\n",
    "                with open(checkpoint_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "                print(f\"Checkpoint saved to {checkpoint_file}\")\n",
    "                \n",
    "                # Calculate and display updated progress\n",
    "                total_combinations = len(optimizers) * len(sub_kernel_sizes) * len(batch_sizes) * len(batch_types)\n",
    "                completed = sum(len(results.get(opt, [])) for opt in results.keys())\n",
    "                print(f\"Progress: {completed}/{total_combinations} combinations completed ({completed/total_combinations*100:.1f}%)\")\n",
    "\n",
    "# Save final results\n",
    "with open(\"Subk\\ernel_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "print(\"Final results saved to Subkernel_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a69096-fcb8-4050-a6d8-8fb43ccca6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
